#+TODO: WRITE EDIT REVIEW | DONE DELETE

* Parasite Suite - Exploring social-computing and art.

* WRITE Abstract

‘Noise calls for decipherment; it makes a reading of the message more difficult. And yet without it, there would be no message. There is, in short, no message without resistance’.

Definitions of the parasite:
1. To one side of (para) the location of the event (site) – the­ medium or being through which communication must pass.
2. The ‘static’ that interrupts the transmission of a message.
3. The uninvited guest or ‘social’ parasite.
4. A living organism that takes without giving as it infects its hosts
5. The one who is always near to food, close to the meat
6. A thermal exciter, that which catalyses the system to a new equilibrium state
­

the following works are a study in the relationship and possibilities in the spaces between communication technology and artistic practice. communications technology and musical practice hold much in the way of a common history, converging and
on a personal level one piece of anecdotal evidence that i have noticed is the large number of programmers and ict (informatin communicatons technolgy) workers that are musicians, composers or disc.

The other piece of anecdotal evidence is the predisposition for composers toward computer programming and electronics.
* EDIT Introduction
** REVIEW Quotes

/“nondiegetic” is really a code word for something else, the infrastructure of the machine, the algorithmic layer, indeed the “outside” of the game in the sense of its social and political conditions of possibility...the nondiegetic is the window into the socio-political realm/ [fn:76]

Nothing that Hackers can do on their own can eliminate surveillance. Just as universal health care is only something that can be achieved by social means, privacy respecting mass communications platforms can only be achieved by social means.[fn:58]

The digital computer “is endowed with the capacity for synthesis, connection and communication, interfacing and exchange, all of which are inherently philosophical or world-bound,” writes Laruelle, explicitly linking computers and philosophy.[fn:57]

"e-mail emerged in 1971 when users began experimenting with ways of sending electronic messages from one networked computer to another. in her study of the internet's origins, janet abbate writes that e-mail "remade" the arpanet system and caused it to be see 'not as a computer system but rather as a communication sytem.'(ref.82) 1.[fn:1]

/this frantic disorientation uderneath the surface is therefor insulated from the user, who is provided with an interactional surface that can be familiar, skeudomorphic, representational, metonymic, flat, figurative or extremely simplistic and domestic./

 For Adorno, reification 'is as much about /forgeting/ certain histories as it is aboit exploitation and preojection' (Schecter 2007: 100).

 These articles are valuable; it is important both to observe how particular technologies function in the world and to point out possible new directions for these technologies. However, a significant dimension of technology goes unnoticed by most commentators: the way of thinking that lies behind the creation and use of technology. If more commentators on technology were able to wade through ‘The Question Concerning Technology’, as well as some of Heidegger’s other writings, they might discover some exciting new pathways for their thinking. [fn:2]

The great breakthrough of ‘The Question Concerning Technology’ is that it shifts the focus away from specific technologies and toward the modes of thinking that lie behind these technologies. However, within this breakthrough lies a danger: it is possible to focus on the thinking behind the technology to such an extent that meaningful distinctions in the world are obscured. In a remark that was originally a part of ‘The Question Concerning Technology’, but was later excised (Harries, 1994, p. 233), this danger manifests itself:

   We know very little about the ways in which software is socially created, the nature of software itself; how discourse, practices, and knowledge get translated into algorithms and code; the geographies and political economy of software development; how software is embedded into various social systems; how software applications work with each other to create complex assemblages that work within and across scales; the power wielded through software's "secondary agency"; and how software alternativly modulates the production production of space and transforms the nature of governance.[fn:3]

   There is evidence that people naturally respond to computers as if they were people. When they work well, we think of them as teammates, and when they are obstinate or rude, we respond to them the same way we respond to rude, obstinate people (Reeves and Nass, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places). [fn:4]

   /According to Heidegger, technology is distinct from what we do with tools, instruments, equipment, or the way of thinking about those things. Likewise, modern technology is not reducible to technological artifacts, devices, or the techniques that produce those things... modern technology in essence is Heidegger’s designation for the way in which things give themselves in and through an epoch. Technology, or what also can be referred to as “technicity,” concerns itself with the ontological way in which things reveal themselves via a “sending”/

/We don’t know what these bits represent, they could be an integer, a float, they could be noted in little endian, big endian, they could be some letter in some encoding, they could be a pixel RGB, RGBA, grayscale, whatever. They could be an audio sample, signed or unsigned. They could be a processor instruction that actually tells the CPU to do something. And these roles can be assigned arbitrarily. Each data point needs additional data about itself, stored somewhere else, describing what is supposed to happen with this data. Then, depending on how the machine operates on these bits, they move towards different meanings. This is why I think it is productive to say: Everything inside the computer is a performance./ [fn:5]
** WRITE Extra Intro Stuff
Unlike recording and broadcast technology, I believe the network offers a kind of 'super-medium'[fn:69], in that the medium offer a collection of other medias, such as newspapers, books, television and radio as 'content', but also native kinds of content experiences such as wikis and hyper-texts, interactive animations, videos and sounds. Ted Nelson lamented that these forms were called 'interactive, online' versions rather than the shorter 'hyper-' prefix which offers a clearer demarcation of how media has adapted to the network to offer non-linear, responsive user-customised content.


    the conceptual inspiration for these works is drawn from histories of early computing, the philosophical influence of early digital design, and cybernetic thought [fn:33], as well as philosophical works about technology and communication. [fn:34] specific models and references for the works are outlined later in their descriptions and documentation. in general, it is the history of cultural metaphors about computation, as well as studies of  technological opportunities that never materialised or fell to the wayside, that have helped me to explore other possibilities for social interaction in computing.[fn:35] by exploring these topics we can see interesting possibilities for restructuring networked engagements with machines. i wish to argue, as has been shown by eden medina in her study of some of the rudimentary techniques explored by the cyberneticians of the cybersyn project in allende's chile, that it is not real time communication of high tech computing that determines the sense of a 'networked experience', rather it is the idea of bi-directional streams of information that are being responded to. this idea is central in much of cybernetic organisational theory, and informs a wide range of practices today. one which i use extensively is the 'streams' programming technique, one that is prevalent in an extensive number of web programs at the moments.[fn:36]

A sincere attempt to portray some of the radical possibilities of computer art when it embraces its lineage and explores the anxieties of the present. These three areas: the philosophies of how machinic interactions have coalesced into one commonly accepted into a common form, a look at unexplored possibilities and under-emphasised potentials in the present, and a search for how to revive those alternative futures, each represent the three strands of artistic research in the project. It is a consideration of what happens when we begin to employ a kind of empathy toward a machinic perspective.

Software as a /super-medium/ that unifies other forms,  (tv/film/radio/print), rather than containing them it reforms and reshapes them into a "new unitary form"[fn:39] "this super-medium acts as both a meditating and structuring frame that we must understand through its instantiation under particular physical constraints" - rejecting the immateriality of software. analysing the doing, platform studies.

the terms 'softwarized society' coined by David berry [fn:40] encapsulates what I see as the outcome of networked experience and computational aesthetics.

As technology inculcates itself we are in danger of forgetting how entangled with computer code we really are, software is part of the narrative of our lives, and yet often overlooked. fuller (2006) notes, "in a sense, all intellectual work is now 'software study', in that the software provides its media and its context..." Berry encourages us to think about the "structure of feeling[fn:41]"  and methods of usefulness permitted by code. noting that technology is a cultural metaphor as well as lexical and physical object. these varied cultural thoughts about technology in relation to the self and society inform practice and engagement with tools as well as wider social and economic relations. to the extent that berry believes the metaphors of software in particular, to form a 'plane of immanence' that shapes relations[fn:42].

in my attempt to consider the design and implementation of tools like computer vision, real-time communication and data-collection, i have often found that the design and user experience as a developer is often imprinted with the culture and expectations of the teams that assembled the foundations of these tools[fn:49]. in a sense i have discovered  a source for my own anxiety in a consciousness of the kind of corporate cultures values embedded in the design of systems. my response to this has been to try and configure atypical user interfaces and methods of engagement, such as avoiding the user metaphor of a person sitting at a computer terminal with keyboard and mouse, and trying to treat sound as a first-class user interaction medium[fn:50].

in this sense the work is inspired by concepts such as 'sousveillance'[fn:51] where a technology is levelled against an oppressor rather than the opposite. in my course of exploring how to 'turn the tables' however, i have also found that it is often the composition of technologies and the relationships that their design encourages[fn:52], that require the formulation of organic and locally specific technologies that offer solutions more relevant in my case for an artistically inspired, more affecting outcome, and on a general level benefit participants.

however the process by which i developed this project was not from a carefully chosen theme, but rather a methodology where i have sought to describe some of the 'back boxes' of communications that i interact with on a daily basis.

** REVIEW Introduction

  'Parasite Suite' is a collection of works exploring possibilities for social computing as artistic medium. Social computing is a concept describing the collaborative aspects of networked behaviour, a developing topic of study in economics, computer science and information systems.[fn:6] It describes scenarios where computed information is created, distributed and extracted across social collectives.[fn:7] Important information is not anonymous, details and behaviour are linked to identities in a lasting way that eventually defines the archive. While acknowledging that all computing is social when we consider the wider world of actors, the project aims to focus on the social relationship between technology and sound art. By studying the experience and materials of social computing I hope to recreate the its fundamental theories in an art gallery context. I believe that understanding of social computing can lead to more nuanced critique and considerations of the material aspects of social computing. My works explores two aspects that I believe are key to understanding the material aspects of social computing, networked experiences and computational aesthetics.

  The project capitalises on legitimate concerns about social-computing, meditating on the sublime tension between awe and anxiety in end user experience. An important quality of social-computing is that the information is indexed, sorted, accumulated, and stored, often to be traded and sold. This allows data to accrue value and use beyond the present moment a user clicks. As information is always 'linked' to an identity, the accumulation and dissemination of this information unfolds in time.[fn:8] I wish to highlight this sense of accumulation in my works and also consider the impact that social arrangements and actions can have on the meaning of this data. I believe that the terms I have adopted, network experience and digital aesthetics each best describe the characteristics and materials of social computing.

Computers can become a tool to describe embedded values that we often do not take time to take notice of. They can also draw new, arbitrary relations, often highly speculative in their reasoning, which is exciting yet also concerning, as results are likely to be incorrect or even prejudiced.[fn:9] Exploring this area using histories of computation and works on computation theory as an interrogation method, I hope to learn more about the development of the 'values' of social-computation. To portray this relationship I will focus on the phenomenological and aesthetic aspects of social-computing, developing sound focused art works.  The works use the gallery as a setting for common social-computing techniques, such as data-logging, meta-data extraction, computer vision and algorithmic surveillance, these social manipulations hope to provoke consideration of the historical use and influences behind many computation techniques. There are many unexplored or neglected possibilities within computation due to cultural bias and lack of reflexively about the medium.

I have been researching two ways technology affects our world, when technology privileges experiences mostly compatible within its own structures and signs (particularly its modes of information transfer)[fn:10], and when it encourages appreciations of the world compatible on its own modes of recognition and reasoning. The presence of these two systems, which I term 'Networked Experience' and 'Digital Aesthetics', are inescapable aspects of how technologies function. However their social and cultural limitations need to be recognised and reconsidered if we are to have any hope of ameliorating the 'false promises of the digital revolution' and develop the more radical potentials of these tools. My small gesture is to reifiy the social manipulations that machines can introduce, and explores these ruptures beyond common computing scenarios in the hope of provoking reflection.

   The starting point for Parasite Suite has been to study common anxieties about the proliferation of these systems, particularly as concerns about institutional surveillance, has taken the shine off much of the sublimity and amazement of networked computing. References for the works include critical theories of the digital,[fn:11] as well as works by composers and artists with an interest in the relationship between technology and society, such as Iannis Xenakis, Włodzimierz Kotoński, Laurie Anderson, Lynn Hershman Leeson, Holly Herndon and Alex Galloway. [fn:12] I believe that phenomenological and aesthetic aspects of social-computation tend to be self-reinforcing, deepening the values that precipitated their own development, to the exclusion of other possibilities. This I term 'parasitism', where technology invites itself as a third participant in all kinds of social negotiations. To me appreciating this parasitic relationship with technology, as both hindrance and possibility for exploration, is the first step in developing new relationships with technology.

   The project is realised as a set of four works that explore social-computing: an installation, an interactive tool, a musical work, and a website. The works contend that humans must be critical of the 'computationality' of the world. The term is a neologism introduced by David Berry in his book /Critical Theory and the Digital/.[fn:13]. It describes an onto-theology informed by the methods of access to information, which Berry argues are networking and software design[fn:14]. Inside compuationality, the methods of access, (through databases, programming paradigms, data transfer protocols and hardware design) develop serious influence over our attitudes to other entities, possibly hindering alternate realms of development. I argue the present computing climate, defined by the tropes of networking and the logic of pattern recognition, predominates relationships with the self and world. As myself willing user, I do not wish to cast this scenario in a negative light, however awareness is a necessary premise for social tensions of computing to be brought to the fore. This concept of a mediated relationship with technology, espoused by Berry, is largely and elaboration to the concept of 'enframing' developed by Martin Heidegger in "The Question Concerning Technology".[fn:15]

   In Waddington's guide to /The Question Concerning Technology/ he explains that Heidegger's work is a breakthrough the way it, "shifts the focus away from specific technologies and toward the modes of thinking that lie behind these technologies."[fn:16] Heidegger also noted that "it is possible to focus on the thinking behind the technology to such an extent that meaningful distinctions in the world are obscured."[fn:17] A remark originally a part of ‘The Question Concerning Technology’, but later excised.[fn:18] 'Enframing' is Heidegger's term for the essence of modern technology. The term describes a danger within modern technologies methods for the accessing truth. In Heidegger's theory, modern technologies reveals truth as a reserve of energy, in tune with the technical paradigms and values of the time (named in Heidegger's terms as 'standing reserve'). We can do nothing about the arrangement of enframing or its influence, it is built into the technology, we can only consider how we will respond to it.[fn:19]  Heidegger doesn't feel that this should necessarily put us off the use of technology, or define it as a bad thing, rather we need to adopt an attitude of 'releasement' (the ability to have a deferential attitude, or apathy, towards the necessity of a technology), that he finds most important.

   The mechanics of enframing are dependant on two kinds of 'concealment', first the operation of a technology is intentionally abstracted by the technology. This abstraction of machinic process allows the technology to be used instrumentally or interact with other technologies, this is often seen in music composition and software design where we abstract complexity or use a software library to focus on a new or previously unreachable area. There is also a second more dangerous kind of concealment, which Heidegger describes as 'concealment of the concealment'[fn:20], it is the taking for granted of a technological abstraction or tool. The first abstraction is treated as a given, or as its own kind of truth, to the point of simulacrum of the representation, such that the technological underpinnings and social epoch are unable to be analysed, doomed to be treated as 'natural'. This second act of concealment is regarded as more insidious, unique to modern technology, and most importantly able to be repudiated through awareness.

     In our parasitic relationship with technology; we use it as a way to advance understanding, yet doing so can dominates our experience and potential. One of the goals of most software is to achieve a simulacrum of 'realness', of the process it is imitating, to the point of being indistinguishable.[fn:17] A successful technology can 'disappear', becoming an unacknowledged part of all experience, this is particularly the case with imitative and surveillant techniques. Studying networked experience and digital aesthetics are methods to reveal instances of the second kind of concealment in common technologies. Through manipulations of techniques and scenario I hope to 'de-black box' a number of social-computing scenarios centred around 'the stream' and 'pattern recognition'. These two dominant metaphors I take as stand-ins for the wider phenomenon of enframing.

** WRITE Networked Experience - An Internet Phenomenology?

   'Networked experience' is my term for the phenomenological aspect of social computing. It is algorithmic processing acts as a facilitators of sensory perception. Video games, pornography, shared coding environments, networked music and robotic surgeries all serve as examples of the emergence of networked sensory systems.  Often a network design is traditional in its choice of sensory paradigms, choosing to emulate past models of communications[fn:70]. However occasionally a networked experience like email messaging radically changes the form of design.[fn:74] Text and images are often the privileged forms of interaction online, a seeming reversal from the dominance of speech acts over texts[fn:65]. This was not part of the original intention for the Hypertext Transfer Protocol, albeit not surprising given its name. Although there is a rich variety of media types on the internet, it seems though it is text that is by far the most 'hyper', in its ability to be distributed, cross referenced, linked and most particularly separate form from content. Aspects of this are open to remedy, and in the sound world this has driven my interest in the Web Audio and MIDI APIs[fn:72] For these projects I wish to explore the role of auditory senses in the network.

 It seems that there is a tension between technologies at present, between the older model of 'hyper-media', that never truly came to pass and the emergent digital metaphor of 'streaming', that has come to predominate. The hyper-media model harks back to the early days of the internet and hippie influenced altruistic concepts such as those expressed in Nelson's book /Computer Liberation/, streaming media by contrast itself is programming and network design paradigms that have been adopted as metaphors for demands on other resources. That is not to say that the technologies are incompatible, I use both in my works, however I wish to point out the media other than text are not liberated from spatial and linear constraints in the same manner that early internet ideology imagined.

 In a corporate model of streaming manages a content 'asset', stored on  a remote server under control by the owner. It is only sent in a piecemeal function as encrypted data. The experience of streaming systems often makes information seem an immaterial vector, with only velocity and direction, and one that can be accessed by turning on a tap and directing the flow. The metaphors of streaming can make all other objects seem like streams of information, waiting to be broken into chunks and waiting for acknowledgement. This can be seen in the emergent paradigms new computer programming languages [fn:24], that emphasise the metaphor of piping, whereby modules are connected to transfer an awaited stream of information. It is as much a response to the challenges of dealing with a new paradigm for the delivery of information an application of a metaphor that was already in peoples minds. Berrys's term for this type of experience is 'streaming-forth', as the network  becomes the characteristic mode-of-revealing of nature. 'Streaming-forth' is an expectation for entities to reveal themselves in terms derived from metaphors about computation.

   It is the experience of the 'stream', that is the defining characteristic of the social-computing experience. A 'stream', shorthand for 'streaming-media', refers to the method of delivery of the medium. It is the technique of delivery that informs the type of enframing the high speed network encourages. The paradigmatic metaphors are 'real-time', and 'flow', both metaphors that think of the digital as moving with trajectories and velocities. It is also a process of 'exhaustion', where a resource is divided into chunks, in the case of TCP/IP delivered into an unpredictable order, with a 'best attempt' at delivery[fn:67], to be algorithmically checked, with bits received, re-requested deleted and re-ordered. It is the computaiton encoding of a post-fordist, 'just in time' re-assembly of digital assets.

   Adjacent to this established technique we have seen the rise of process piping and streaming taken from systems, mocing into the realm of sfotware design.[fn:68] This process is infecting approaches to other areas as software companies attempt to bring their approaches to software to displace traditional intitutions. Berry terms this mode of thinking about acdess ot the world, 'streaming forth', where the demand placed on the world is that of constant generation re-ordering, processing and collection, rather than the challenge-response model of Heidegger. I think of it as an algorithmic approach to the senses. This  mode of experience isn't dependant on any kind of technology or state of development, it is possible to create a these kind of experiences entirely with a set of human relations. This was the case with Cyber-Syn a 1970's project by the Chilean government to create cybernetic economic systems, modelled on the human nervous system, realized by and large without computer access.[fn:22] Streaming describes an attitude towards access to resources, it is an enfraing we expect the methods of access for streaming to apply in all our relations.

 This sensory approach, applied to computing, is closely associated with both cybernetics, as shown in Eden Medina's study of early attempts art providing experience of the economy as a nervous system in Peron's Chile.[fn:21] The network experience is often a flawed fantasy of the eternal present, where the individual instinctively responds to events in a consumerist haze. However there were wider possibilities, such as those that were the original intention of the Cybersyn network to provide multi-faceted levels of experience and direction, with attempts to emulate cognitive, self-sustaining and pre-emptive modes within the different levels of the cybernetic organisation. I wish to argue that it is not the mechanics so much as the purpose for the use of these tools that is lacking. 'Streaming' tends to engage in concealment of resources, transport mechanisms and ironically, other users. This can be seen in the somewhat humorous technologies such as 'The Twitter Sort,'[fn:23] and the word processor Soylent[fn:62], "The word processor with people inside," where users of Amazon's distributed micro-labour system Mechanical Turk[fn:63] perform word processing operations. Rather than rejecting the phenomenon (which I feel is impossible) I am interested in what aspects are open to social manipulation when this kind of thinking is dominant. The easiest way to decide what elements to focus on are to look at the concealment that a technology makes. I think that accumulation and memory are the first to be ignored, as are the material needs of a technology.

   I beleive this is because networked experience extends beyond interaction with computers, into a metaphorical 'revealing' of the world as a network of social scenarios, able to be connected to and manipulated at will, so long as users are cogniscent of the rules. This kind of ethos is enabled by the design values embedded in computer hardware and software, as influenced by the Californian ideology and the notions of individualistic libertarian impulses that theory entailed.[fn:59] Network technology under these paradigms imbues it with a particular kind of immediacy, but also a sense of danger. It is a de-regulated system that places a heavy burden on users to manage and secure all aspect of their online identity.[fn:61] The contradiction that we often use networks to maintain the notion of individual identity, which is often where it is taken away, seems strange, but I believe the implementation of values in software and hardware is the reason. This is no conspiracy, simply that the standard practice is to reproduce and emulate the models of the past, and programmers are often excellent at emulating a narrow range of design patterns.[fn:66]

   Exploring this tension between streaming, sharing, surveilling and hyper-ing is where my project is currently at. Is music an asset, content, form etc. I wish to see the realization of an interconnected stream of audio that can exist at multiple levels of detail, with links to references, branching and responding. I wish to explore the sensory process of the stream, how it fits into social surveillance and hyper-media, to combine these into a kind of fused media that uses some of the inherant contradictions in the 'feeling' of the stream.

The phenomenology of a hyper-streamed-sound thus bear the followng characterstics:
- memory as it is experienced in the moement
- layered experience, spatially non-diagetic
- experiments with interface, multilayed
- a focus on the sensation of memory in a variety of forms, as false, shared, non-linear and spatial.

** WRITE Digital Aesthetics - Computational Ontology

   In contrast to the immediate aspects of networked experience, digital aesthetics are the lasting effects of social computing on reasoning and judgement,[fn:56] a rupture of the digital into the real. Often termed 'pattern aesthetic'[fn:26], or 'the new aesthetic'[fn:27], these trends describe widespread cultural shifts in appreciation of objects that bear a hallmark of their interaction with computer algorithms. The most noticeable of these are nostalgic references to older computational limitations, such as pixelated artworks and chip-tunes[fn:75], but popular trends in architecture, photography and music also bear signifiers of digital logic, often by artists the highlighting of the presence of digital tools. Hito Steryl notes the impact of digital modelling tools on the designs of Frank Gehry[fn:78], similarly the history of dance music shows a particular desire to highlight the impact of tools. David Berry names this 'Abductive Aesthetics', arguing that the logic of software design inform the 'look' of the digital rather than the popularity of a particular style.

   Abductive reasoning, also known as inference to the best explanation, is an approach to reasoning which attempts to test a hypothesis based on the information at hand, refining the set of best guesses as the quality of information improves, though more processing or data accumulation. It can be contrasted with deductive (proof-based) and inductive (evidence based) reasoning as the 'fuzziest' kind of reasoning, somewhat akin to a 'best guess'. It is ubiquitous in its use by computers, one of the most well known examples of an abductive algorithm is predictive text on cellular phones, but abductive reasoning is everywhere in computing. Early research on artificial intelligence focused heavily on the use of abductive reasoning [fn:30]. The reasons for doing this were to establish functions that could handle large data sets without having to maintain state. Maintaining state is akin to extra steps that monitor a linear progression of events for conditions to be satisfied. Abductive reasoning emphasises the spatial over the temporal.

I am seeking to apply abductive logic as more than a tool by looking at its form and social impact. Abductive reasonings use as a real-time guessing tool nature belies its close relationship with network experience, the stream provides the resources and the abductive the logical machinery to transform it. Suffice to say they that in modern usage have a mutual dependence. The reasons for doing this... =whyyyy are similar to the reasons for streamings current methodologyu..= Abductive patterns scale to massive data sets well, with the downside that their functions often leave a distinct 'pattern', when their use is repeated or data sets are flawed. For this project I wish to explore the application of 'digital' logic to artistic and musical composition and its resulting aesthetic, as well as possibilities for reaching beyond this. Applying abductive reasoning to music, the resulting aesthetic experience can be described as conducting a 'pattern language'. A pattern language is where we communicate and recognise according to the abductive reasoning, by recognising broad suppositions and rapidly testing hypothesis by jumping to conclusions until all our tests for truth pass. To act abductively with music, I believe we need to design musical systems that collect information and respond with a 'best match'

A 'pattern language' is something that we can be aware of, but whose methods tries to make itself 'transparent' to us. this appeal to transparency goes beyond the user interface level into all manner of abstractions at all levels of coded space: interfaces, application programming interfaces(apis), objects, macros, function composition, integrated circuits, all exist as abstractions that can make an processes result seem more natural when they hide away complexity. these tools are crucial for managing all of my projects, however the cumulative effect of these tools, often appears as a kind of 'magic' to the person using the tool to prepare an experience, and as a kind of faux 'natural' to the end user, who is intended to be none the wiser. 'Computationality' can then be experienced as a combination of computer processing and networking capability that embody a particular aesthetic and mode of experience for those that interact with the works [fn:31]. the particulars of the experience and aesthetic of 'computationality' has been specifically collected and outlined by others[fn:32] but i loosely define it as the experience of a real world decision that seems influenced or largely determined by by what would be appropriate for the algorithmic sensibilities of a machine rather than a human sense of design aesthetic. the manner in which this is realised. a particular aspect of the 'computational' i have focussed on is the felt sense that a machine can be treated as a participant and social actor rather than a tool.

   Similarly to my comments on network experience, what abductive reasoning tends to bring to logic is non-linear patterning. Abductive recognition does not focus on the timeline of events, to find an implication, but rather on the spatial characteristics of a set of values, for instance if they match the qualities of a matrix template. The aesthetics of abductive resoning can be thought of as consisting of several model types, each with their own charcteristics, but a common thread of convertng actios over time into a spatial arrangement. These pattern matching patterns, are broadly outlined by Berry as, template-matching, prototype matching, feature analysis, recognition by components, fourier analysis, and lastly bottom-up and top-down processing.[fn:79] By using abductive reasoning as a composition tool we can see the process of recognition in action, and begin to think about its affect. The characteristics which I wish to bring to my art works are those of spatial, speculative, =probabilistic=, generative. Consider a algorithms image of the world, and what these algorithms generate for us.

 /Each pattern is a rule which describes what you have to do to generate the entity which it defines. (Alexander 1979: 181-182)/

** EDIT Historical Studies

 To content witht he atemporal, ever present characteristics of computations, I would also like to include some reflection ont he history of this approach to thinking, and the abstract, often individualistics patterns that it follows.

The lineage of the personal compuet, so ubiquitous today, of the the 'california ideology' on interaction with computers today seems to enforce the idea of engagement with a computer being focused on having one operator, holding tight deterministic control over one program utilising an acceptable set of input and output techniques. I believe that lineage is reaching both its apothetis and point of crisis.

Followin the work of Radical Software Group,.... I wish to make a study of these forces of technoligical ideology and incorperate it into my artworks. I hope to reintroduce political ideas into the discussion of technology by reintroducing the social and political into the musical and technological landscape.

i argue that there is a link between some aspects of the transhumanism which has influenced much of technological design and desires of transcendence in 20th century music compoers such as john cage that has emphaised transcendce at he expese of 'silencing the social' in the wods of douglas kahn. it is not my wish to decry these works, rather to celebrate and reconsider them in the context of today where we are never sure if we are too connected and being surveilled, or too alone and alienated. instead by seeking o re-empahises teh socaial, collaboratvie aspects of that is already there instead by seeking o re-empahises teh socaial, collaboratvie aspects of that is already there.

as this project, determined in looking at 'possibilities', has a somewhat futuristic bent. i have elected to be somewhat wary of the degree to whih i cast the future in the mod eof my own emplacement. this circular inevitablility of conditioning my works into a kind of 'future-present' is somewhat inescapable. however in an attempt to mitigate this i have tried to take inspiriations for my work from other 'failed utopias' as much as the one i currently reside in.

in looking to early expectations and the failed dreams or unexplored possibilities of early omputer history, particulary notions of socialist computing, artificial intellignece, cybernetic surveilland and hippie counterculture, along with the ideas of modernist music composer such as xenakis, berio and stochausen, who all had similar utopian notions about the future of both society and their art.

the cybersyn surveillance project of allende's chile, the cybernetic counterculture of 1960's san franciso and

i have instead looked at other failed utopias. since this work is a study in the effects of networking and computation.

exploring some of their neglected meanings and history of terms and contrasting that with where the emphasis of specific definition lies today is a key part of the work. by looking at the complete history and meaning of terms, particularly alternate meanings, i feel we can begin to excavate other possibilities, possibilities that were always available but feel cut off from now.

for example, the word computer has a been on a historical journey from meaning a human being that makes calculations, to a device facilitation calculation. however even the interesting parts of that statement miss some of the socio-cultural aspects of what a being a computer means.

for instance that computers were once large teams of people used in warfare to calculate distances, supplies and give reckonings for artillery. or that later computers became numerical analysts, a job that was generally gendered to be for women, and teams of women were given the task of managing early machine-based computers. (hmm prob not necessary, incl. refs).

how to portray this rich and often conflicted history in a word is a difficult task. we see that  a key role for the artist can be excavating meaning. looking that the meanings that have been applied over the years and following a common task in critical theory, asking why certain aspects have traditionally been ignore, or taken as a given. because of this, to begin my process i have given in depth listings of the meaning of key terms for the suite of works.  a dictionary definition offer a reflection on the range of meaning and the suggest links to the history of what are seen as ‘modern’ terms. i am seeking to try and combine and undermine these terms to try and understand my own position.

* WRITE Parasite One
** Summary - Inspiration for Work.
   Micheal Snow - Wavelength
/the GUI creates spatial continuity through the simultaneous windowing of different spaces: instant messenger, browser, file-sharing client, programming IDE, game heads-up-display. Fusing cuts within the frame replaces fusing cuts in time. But is this surprising, given the inherently networked quality of spatial montage? Windows are objects; they form as nodes into graphs on the screen; they may or may not interconnect; and so on. The rise of spatial montage is therefore just another way to describe the rise of the networked form of mediation overall./

/The montage example demonstrates how important the nondiegetic is in digital media. The frame — previously marginalized, a veritable mark of the avant-garde — is now entirely normalized, an everyday occurrence in media aesthetics./

/In this way, to stress the relation between diegetic and nondiegetic game play is to stress the question of interfacing. Indeed thresholds occupy a very special place in informatic media. One might go so far as to say that informatic media are nothing but a set of thresholds, layered and nested in chains of systems and subsystems, shells and still greater shells. This again is why the nondiegetic is so crucial, because: (1) it underscores the fact that informatic media are much more overtly structural and formal than previous media formats (while still not ceasing to be material); and (2) that because of the intimate relationship that informatic media have with actually existing material structures, they beckon toward a political understanding that is more vivid, more readily accessible, and more raw than in the past. We have, in short, a medium that tells its own story through the interface itself. One must simply be ready to listen./ [fn:77]

The work is focussed around exploring the idiosyncrasies of networked real time communication in the context of a sound art tradition.

The principal sources of inspiration are a re-interpretation of John Cage’s Imaginary Landscape Number 5 (link). My re-imagined take on the work is also inspired by the oblique networking system of the video game Dark Souls (link appendix), as well as the ‘giant’ piano featured in toy store sequences from the movies Big(link) and Lethal Weapon(link).

The initial version of this installation takes place on a staircase with eight stairs. Each stair has a simple floor trigger underneath and adjacent light source to light up a user's feet when they activate a stair.

Each time the program is run that controls the stairs is initialised the stairs are given a sample to continuously loop from a randomly chosen collection of audio files on the installation computer (link to script for sample picker) to act as its streams.
Under the staircase is a speaker playing eight pre-arranged ‘streams’ of sampled information, the volume of each stream, corresponding to stair, is controlled by the floor triggers.

There is also a website for the installation where users can log on to observe and listen to the installation. Access to the website also offers users two pieces of added functionality. After allowing access to users microphone and camera, they can now trigger staircase responses remotely by hovering over a box representing each stream. However by participating in this manner the user becomes part of the installation, the sounds of their microphone stream replace those of one of the stairs in the installation for as long as they are visiting the site.

Realisations
(Video)

Implications

The work attempts to deal with some of the major themes of the collection of works. Namely by looking at surveillance and the idea of ‘engagement’ with the surveyor. The work attempts to press the

Experience

The observed experience is markedly different for the two kinds of participants in the installation as they assume different roles, In-situ visitors are usually at first surprised by the manner of the

** Technical Outline
*** Intro
The installation parasite is a work that occupies a staircase, using 8 floor panel sensors constructed from conductive material and plastic to form large ‘buttons’. These ‘buttons’ are placed under pieces of carpet and wired to an arduino microcontroller communicating with a small desktop computer.

The computer is set to transmit sound within the space using the audio capabilities of html5’s javascript application programming interfaces (APIs) and the microcontroller messaging and web serving capabilities of the node.js server side javascript language.

What is immediately obvious to the participant is that the computer is set to send messages to turn on 12 volt LED strips attached above the stairs, these light up as participants stand on the floor sensors. The computer is also outputting 8 muted streams of audio, a corresponding stream also having its volume increased also when a user stand upon a floor sensor. A the top stairs visible to those ascending there is a handwritten universal resource locator (URL)
directing those who are interested to visit a web page (currently: www.parasite.ngrok.com
(diagram of installation)

all source code available at https://github.com/brookemitchell/parasiteChat

*** Physical Computing - Arduino Circuit

In the spirit of ongoing development, the circuit constructed is simple enough to understand and designed to emphasise direct user input with highly responsive feedback prioritised above consistency of user experience. Sensors are expected to  register input instantly, resulting in the ability for the user to trigger results multiple times simultaneously by adjusting the weighting of their feet or coerce buttons into a ‘stuck’ state by carefully removing weight off the floor panel. These kinds of user ‘hacks’ and edge cases are encouraged as part of the art work rather than erased by attempts to enforce  total consistency of user interaction.

(img – circuit diagram)

The floor sensors that serve as basic buttons are connected to eight digital inputs on the arduino, using the internal pins of each pin to serve as pull up resistors and create a typical ‘button’ input circuit. To control the lighting eight digital outputs send 5v control voltage signals to eight N-Channel MOSFETs (link). The MOSFET transistors have 12v voltage provided by a separate power rail that is gated by the MOSFET, as controlled from the arduino, a  a corresponding LED strip can be illuminated whenever 5v control voltage is sent from one of the digital out pins.

The firmware of the Arduino is then uploaded with the Standard Firmata microcontroller library (link), which allows for the microcontroller to interpret midi messages over serial.

(Communications Diagram)

*** Server side programming - node.js: express, logfmt, johnny-five and socket.io

The server, a small computer connected to the microcontroller, manages the major communication aspects of the installation, those being communication with the arduino, handling html web page requests and bi-directional webSocket communication with users once the page is sent. These three aspects are each handled within the node.js server-side javascript language by three module libraries,  johnny-five (microcontroller messaging), express(serving dynamically generated web-pages) and socket.io (webSockets management). In addition to this a small logging system is used to store user behaviour for later analysis and a database and archiving system exist to store user messages and video archives.

*** Johnny-Five (link)

The Johnny-Five library allows node.js to communicate with the Microcontroller by sending midi messages over the serial bus to the arduino. The requirements for the arduino in this instance are to register any floor sensor button presses, log them and then send an ‘on’ message to the 12v LED strip corresponding to the panel. The second requirement is to also send this message on to the webSocket management system, to be broadcast to all users. The final requirement is to also receive any messages from webSockets that direct the microcontroller to turn its LEDs on and do so. This third requirement enables the arduino to receive messages from remote participants, in this case so that visitors to the web page can control the installations light and sound by hovering over different buttons, simulating in-person participation.

(img 10 liner johnny-five code snippet)

*** express

Users who visit a web page a served a web page from the installations computer. This page contains the current user numbers of the chat room as well as the necessary authentication tokens for them to use the video chat. To provide the dynamic content the express middleware generates the html necessary. In this case the process is relatively simple, with the content being a  largely static page augmented with dynamically generated user tokens and statistics, as well as the last ten chat messages as retrieved from the database.

*** socket.io (link)

The socket.io library manages webSockets providing a more manageable abstraction for dealing with aschronous realtime messages. As the name implies, the library forms the core of the input/output messaging system of the installation by relaying messages in real time between disparate users and the server. The library can therefore manage all aspects of the chat application and user hover actions. Keeping track of users and their states and broadcasting these messages to all participants as well as broadcasting button triggers on the stairs to all website users.

*** Logging

A simple but key aspect is the ability to accurately log events for later analysis and compositional practice.. In this case a user logging on hovering over of standing on a  step are all given a date and time stamp then logged to a text file. Further user monitoring is handled on the client side by cloud based services firebase.io (link) and openTok (link).

*** Database & Archiving

Chat messages are logged to the cloud base fiebse service as they are received. This provides a complete text archive of all messages that can be acessed using an api from anywhere. Allowing the server to send clients the last ten messages to provide context and possibilities for analysis of the data to inform compositions. Similarly the server-side aspects of the openTok real-time-communication for video library offer a convenient way to archive video chat usage, which is then uploaded to a cloud-based storage instance provided by providers such as microsoft azure or any cloud provider that is currently offering discount cloud computing such as amazon ec2.

*** Client Side Web Programming - Chat, Video and Web Audio


The web server provides two web pages, one outwardly facing root of the web site, which serves the main client side application, a chat room with real time audio/video communication. The second page (henceforth referred to as the ‘host’ page) is served is at  an undisclosed url that provides audio functionality for the staircase and intended only for use in a scenario where a computer is connected to a webcam, speakers and microphone, although the possibilities of ‘hacking’ the host page is left open due to its publicly accessible address.

The ‘host’ page is primarily designed to contain a web audio API ‘audiocontext’ (link to appendix describing web audio api) that is controlled by webSocket messages to turn gain nodes on and off, a buffer and gain node corresponding to each step. This buffer initially contains a long (8 minutes or more) field recording. As users step on floor sensors or web client users hover over a set of 8 boxes , the corresponding gain node of a stair is un-muted.

For further explanation of the webAudio API system please see appendix 1.

(webAudio context diagram of internal signal flow)

The ‘host’ pages user functionality is minimal and specifically designed around the needs of the installation, providing appropriate responses to websocket messages by raising the gain of audio streams if told to by the server or another client. Despite the possibility of

(Video of ‘host’ page demo showing gain being added on step or user hover)

* WRITE Parasite Two
** Summary
Parasite II is an attempt to incorporate computational and networked approaches to photographic intelligence as a method for musical composition. While Parasite I focuses on communications intelligence and interpersonal relations, Parasite II is centred on Photographic Intelligence [PHOTINT] as a musical method and inter-application communication within the machine.

Also commonly known as Imagery Intelligence [IMGINT], this kind of intelligence and analysis is commonly associated with Satellite photography and drone warfare. In this installation I seek to use methods derived from the history of technology in this field in order to create visual consideration of landscape and topology that become musical environments.

The setup for this installation involves a large glass box containing white sand, with speakers and a computer placed adjacent.  Above the sandbox a projector and depth sensing camera are mounted. The camera senses the topology of the sandbox surface beneath in and overlays a series of topological data such as relief contours, height maps and rainfall patterns. Details of the software environments adapted and used in the installation are given in the technical specification.

Part of the creative inspiration for the project is in the arrangement of communications between disparate software programs. as they share their contexts as they seemingly operate in parallel. Each program uses the same sensory information but styles it using a different logic and syntax that informs the audio and visual outcome. This is an early form of what Manuel DeLanda has termed a ‘Pandemonium’ (link). In its ultimate form according to De Landa, processes would operate as small modular forms of artificial intelligence. As it is experienced in the gallery context, the sensation of affecting both audible and visual landscape is hoped to be both thrilling and mildly sinister.

The other aspect of the inspiration is to see what the experience of empowering the participant with the ‘birds-eye-view’ means in the context of the art gallery. Structures and systems can be difficult to perceive but here the participant is placed into the role of composer of landscape on a macro level and given a kind of god like power over the environs. Because of the closed loop nature of the response relationship between projector, sand and camera it appears to the user as if all actions are controlled by the human controller. However it is really a careful management of shared information and state between computer processes and sensors that enables this kind verisimilitude. As such such this work is also a kind of [SENSINT], a less well known kind of surveillance that depends upon developing intelligence from mechanical sensors placed in the field.

(subsction) - SENSINT and Early Electronic Music.

The sound sequencing and rendering system is heavily inspired by the work of Iannis Xenakis. Both in the adoption of existing concept and software as given in his book Formalized Music (link) as well as an interpretive glance at extending some of the possibilities by looking at topology as a compositional practice
** Technical Outline

Parasite II Summary
(installation image)

Parasite II is a audio/visual installation that combines a visual topographic rendering with a sequencing and synthesis system. A projector and depth sensing camera are mounted over a box of sand, connected to a computer and speaker system. A topographic relief map is projected onto the surface that is able to be interactively ‘reshaped’ by the user. This ‘landscape’ informs the process of a topographic sequencer modelled on the work of Iannis Xenakis to inform a probabilistically variable series of sequenced sonic events. The contouring of the landscape creates multiple levels of sonic event, macro level arrangement, meso frequency of occurrence and micro level synthesis.


The installation consists of a open top glass box of dimensions 0.75m x 1m x 0.15 depth, filled with 50 kilograms of white sand. Directly above the box a short-throw projector and depth sensing camera (Microsoft Kinect v.1) are mounted. These are connected to a desktop computer running linux with a graphics card and audio output.

(Diagram)

The visual rendering software is SARndbox,  an augmented virtual reality system developed by Oliver Keylos at the University of Davis California (link) The software forms a closed feedback loop with the calibrated information from the depth camera and renders topographical data in the form of a dynamic relieve map onto the sand surface. This topographic rendering can be dynamically altered by users altering the depth and contours of the sand surface. Water flow simulations are also rendered when the algorithm (link) determines the depth or contours capable of  containing a body of water.

(Video of user interaction)

Kinect Data

As data from the depth camera arrives it is sent to Oliver Kreylos Virtual Reality User Interface (VRUI) system (link). This software acts as an abstraction between the device driver and the application handling of the information, allowing the application to act as a server that sends the data of to its visual system of SARndbox extensions for the program as well as to other applications, in this case a custom compiled version of Iannix(link) that sequences the audio subsystem.

(diagram of a/v software communication system)

Visual System

The visual system is largely handle by preexisting software that only needs to be compiled and calibrated, a time demanding but well documented process. Custom relief colours and depth ranges edited in configuration text files following a hardware, then software based camera calibration process (see appendix). After this the rendering of relief features is also calibrated to have the measurement and projection systems aligned with a high degree of accuracy (< 1mm under ideal circumstances).

Audio Sequencing System (Macro and Meso Level event triggering)

The signal from the Microsoft Kinect is also sent to a custom version of the IanniX (link) three dimensional sequencer software. The software is a modern implementation of Iannix Xenakis HPIC visual arrangement system. (for more details describing the structure of UPIC and Iannix programs see appendix c). This custom compiled version of Iannix allows input from a  kinect camera to control the shape of curves along which travel cursors. The position of a cursor is relayed over OSC to  the audio rendering system (Micro Level), collisions between curves are also able to be detected to form Meso level events.

Audio Rendering System

At present various audio synthesis methods are being explored. The two techniques being explored are to use an additive synth,  directly mapping frequency to the x axis, gain to the y axis and an effect to the depth (ugh re word - testing has taken place)

The second option being explored is an implementation of Iannis Xenakis’ GENDY stochastic synthesiser. The GENDY system will map sets of control points to contours of the landscape, with elevation determining the event distribution and

The ultimate goal is to implement a stochastic sequencing system utilising the


At present the

(10 sec video demo of Kinect > Iannix)

and and video output to

Audio Sequencing System

CosmosF

Description.

* WRITE Parasite Three
** Summary
Parasite III is a performance work that takes a collection of the materials collected in the other works and uses them to explore the real time possibilities.

The purpose of the work is to give a  concise, live performance work that attempts to convey some of the themes of the other installation and to embed myself deeper within the practice of considering networking and computation as sufficient metaphors for musical practice. Part of the practice here is to try and articulate the practice of Systems Analysis. To take a collection of data and real time streams, as well as a context and personal experiences, and articulate a real time summary of the mood and meaning relevant to an audience.

In this way the work seeks to look at the idea of ‘information’, and the shaping of messages, as a hybrid process in which aesthetic choices, technological capabilities and social signalling processes are all complicit. It is hoped by choosing ‘alternative’ and more experimental practices for live performance, that some of the common tropes and negotiated meanings that are also in more regular practices can also be noted.

The complete setup and a set of recordings are given in the technical section.

(Give example score)

In a general sense, the work follows an interest in the idea of the human as computer. The word itself once mean simply a person who does calculations. The term has a gendered and social history. A computer used to be a person on a large team that would be tasked with making calculations and giving reckonings, as it was a key job during warfare. They later became teams of  women that would prepare programs, maintain machines and input the code.

Here the concept of the work is to act as a node, linking three other streams that represent the other works that make up the parasite suite and extending or re-configuring them when necessary.

 (intro into this?)
The work borrows the concept of a ‘possibility space’ from the world of video games. The initial state of the world and areas of concern are shifted with each initialization of the work to create the software’s game world. As with the other installations, there is a designation of syntax by the composer prior to the performance, here ordered around the type of sound elements, controls available and the conception of an ‘ideal state’, however the expression or, ‘path-finding’ of how to achieve any goals is varied and different for any performance. The performance focuses on the performer extracting the emergent properties of the software and finding a manner to interact with the ‘possibility space’.

** Tech Outline
Parasite III is a performance piece that makes up the third part of the series exploring computation centric sound generation and networking.The performance elaborate on the concepts from the first two pieces, utilising the networked streams of information from Parasite I and the stochastic sampling and synthesis methods from Parasite II as part of a live, improvisatory performance.

Channel 1

The performed work uses four channels of information to be rendered into a stereo output. The first channel is a series of samples which are rendered from the chat logs of the Parasite I installation. Interesting vocal excerpts are rendered using the voice synthesis software Vocaloid (link). The merits of vocal excerpts are currently chosen on the basis of aesthetic preference, although an automated stochastic approach is to be tested in the next performance.

More detail about CosmosF

The samples are played basing using the CosmosF stochastic Sequencer and Synthesiser developed by Sinan Boksoy (link). The software is an aesthetically opinionated interpretation of the work of Xenakis in Formalised Music to have a multi level (micro meso macro) stochastic sequencer that also contains a stochastic synthesis engine and represents a massive effort into developing the concepts of stochastic approaches to music by Dr. Boksoy. I take a limited approach to utilising the software, focusing exclusively on the use of samples whose duration and onset are stochastically controlled. The relevant parameters are mapped to a faderfox FX3 controller.

(diagram controller mapping)

Channel 2

The second channel uses an instrument designed specifically for the performance, the Firefader (link) an open source haptic interface developed by Edgar Berdhal. The instrument is comprised of two motorised faders with capacitive sensing to ascertain when a user touches one of the faders.the physical modelling of objects then able to take place in software and should the computation time be fast enough, low latency messages sent back to the motors to enable highly realistic modelling of the physical object. (See appendix for more info on the Firefader).

The firefader is connected to two max/msp patches based on example patches from Berdhahl's course in open source haptics. The first uses a series of arbitrarily tuned resonator connected to a spring model to somewhat emulate a steel object. There are four springs and resonator combinations placed near the four upper and lower limits of the firefader. For this instance the frequency and harmonics of the resonators are each tuned to match important frequencies of an arabic maqam mode that will be placed to accompany the piece. In the next performance other tuning schemes will be explored, likely to match an analysis of the vocaloid excerpts.  Further experimentation is still needed.

The second possible patch that is available for the fireFader is a simple implementation of a phase vocoder that allows the user to scrub through the waveform of the samples utilised in channel one. The phase vocoder for fireFader read teh sample input and assigns weights to virutal masses along the path of the fader on the basis of sample amplitude (see appendix on virtual modelling of physical systems).

Channel 3

The third channel is a simple monophonic digital synth that is controlled by a small keyboard. The keyboard controls a simple max/msp patch based on the Hijaz patch from Sufi Plugins built by Bill Bowen (link). In this patcha  single cycle waveform is split into three frequency regions (low, mid high) and each is randomly wave shaped. The resulting sound is able to be played by midi, with custom tuning options for any 12 note scale able to be into. Crucially the keyboard in use with this channel is one with per-note pitch bend,


 The keyboard is able to register per-key

* WRITE Parasite Four

* WRITE Conclusions

  Question of even presenting the material. Is digital art a 'performance', I would argue it is, and that there is a neglected temporality.

  Danger is in emphasising mastry over and about understanding. How over why. Computers are always social.

  Technology as more medium than instrument, instrumental thinking as problematic.

is particular association is identified in “The Question Concerning Technology,” where Heidegger says that as long as we perceive “technology as an instrument, we

remain held fast in the will to master it.”9 A similar theme is taken up and examined by Heidegger in What is Called Thinking?10 Within this text, Heidegger pronounces that Nietzsche’s overman represents the embodiment of pure technological being, insofar as the overman’s will is a will that strives to dominate and master anything that is other.11 Heidegger feels that the overman is not an anomalous phenomenon in the modern technological age. All those who live under the sway of modern technology have to confront this reality. Within the periphery of the epoch of modern technology, “the only thing we have left is purely technological relationships.”12

  The end goal is the hope tat users will envisage teh ways in which existing social engagements can be 're-tooled'. The 'hack' of technology is often not highly technical, instead it is a re-visioning of what a technology could be useful for.

* WRITE Extra Notes

*** Look at study on Links

jockeys[fn:55].
*** WRITE Graph of structure of Computationality

Networked Experience() ->
Abductive Aesthetics() ->
= Computationality ()
both combine into set of qualities

(Berry on Twitter [p. 76])As a form of computational media that is highly social, it presents an interesting case study in relation to our public/private experiences of communication through a computational platform.

   In this respect human relationships with technology occupy a somewhat vexed space, with technology seen as both 'means to an end', a tool of progress or improvement, yet perhaps more importantly technology is also a medium through which we experience the world.

* Footnotes

[fn:1] edina 64

[fn:2] Waddington 576-577

[fn:3] (Kitchin 2011: 946)

[fn:4] Think python p. 7

[fn:5] DEFINITION NOT FOUND: fn:4

[fn:6] Wikipedia social computing https://en.wikipedia.org/wiki/Social_computing

[fn:7] From "Social Computing", introduction to Social Computing special edition of the Communications of the ACM, edited by Douglas Schuler, Volume 37 , Issue 1 (January 1994), Pages: 28 - 108

[fn:8] From "Social Computing", introduction to Social Computing special edition of the Communications of the ACM, edited by Douglas Schuler, Volume 37 , Issue 1 (January 1994), Pages: 28 - 108

[fn:9] http://www.slate.com/articles/technology/bitwise/2015/01/black_box_society_by_frank_pasquale_a_chilling_vision_of_how_big_data_has.html

[fn:10] Paper on organisation structure affecting software design

[fn:11] Theories of the Digital

[fn:12] Put refs for all tehse people here

[fn:13] 'Critical Theory and the Digital'

[fn:14] Heidegger notes in /Being and Time/ that the priveleging of the present has a *parasitic* relationship with the concept of time. This could be extended.

[fn:15] heidegger qct

[fn:16] Waddington 577

[fn:17] Waddington 577

[fn:18] (Harries, 1994, p. 233) IN Waddinton 577

[fn:19] Enframing Heidegger p.2

[fn:20] Second ceoncealment Heidgger

[fn:21] Cybernetic Revolutionaries

[fn:22] ref to dependdence on human actors in cybersyn

[fn:23] Twitter Sort

[fn:24] Streams Programming Languages

[fn:25] All yOu need is data DTD

[fn:26] Pattern Aesthetics

[fn:27] the new Aesthetics

[fn:28] Against the digita

[fn:29] google autocomplete suggestions description link

[fn:30] link between abductive reasoning and ai.

[fn:31] link to uses of term

[fn:32] link to new aesthetic site / files

[fn:33] link to weiner

[fn:34] link de landa, berry.

[fn:35] idea taken from the talk,"the web that wasn't" )[[webthatwasnt][twtw]]

[fn:36] link to deetails on javascript streams

[fn:37] whats a daemon yo.

[fn:38] berry 10

[fn:39] berry 10

[fn:40] softwareised society, link opening of phil of software on dependance on software for survival. berry p.

[fn:41] berry, p. 6.

[fn:42] berry and deleuze, p. 18.

[fn:43] berry p.62

[fn:44] software is eating the

[fn:45] link to treer main history book / topics

[fn:46] stoch to xenakis quote

[fn:47] link five eyes surveillance

[fn:48] def of

[fn:49] link to classic essay about design of saftware informed

[fn:50] any links to this? there was a bit from deland

[fn:51] sousveilance

[fn:52] foucoult link, design of software and oppression

[fn:53] functions in programming.

[fn:54] computers and society

[fn:55] u[fn:5] http://rhizome.org/editorial/2014/oct/22/big-data-little-narration/

[fn:56] (digression on culture)

[fn:57] cultureandcommunication.org/galloway/laruelle-against-the-digital

[fn:58] www.dmytri.info/hackers-cant-solve-surveillance/

[fn:59] Link california ideology works

[fn:60] www.dmytri.info/hackers-cant-solve-surveillance/

[fn:61] /The visions of a free, uncensorable cyberspace envisioned by Barlow, Gilmore and others was incompatible with the needs of Capital, and thus the libertarian impulses that drives Silicon valley caused a change in tune. Cyberspace was no longer a new world, declared independent with its own unalienable rights, it was now an untamed frontier, a wild-west where spooks and cypherpunks do battle and your worth is measured by your crypto slinging skills and operational security... This, as Seda Gurses argues, leads to Responsibilization... Users themselves are responsible for their privacy and safety online. No more unalienable rights, no more censorship resistant mass networks, no more expressing beliefs without fear of being silenced. Hack or be hacked./[fn:60]

[fn:62] Soylent web site

[fn:63] Mechanical Turk

[fn:64] google Auto Awesome, recreateing memories

[fn:65] See Derrida Text v speech.

[fn:66] repetition of design patterns

[fn:67] See the deisgn of TCP/IP, also md5 sums

[fn:68] See streaming in js, matz pipe language

[fn:69] Berry on 'super-mediums'

[fn:70] Ref to Application layer of TCP/IP

[fn:71] Some more shit on derrida i guess

[fn:72] Web Audio API

[fn:73] Uncanny Valley

[fn:74] /E-mail emerged in 1971 when users began experimenting with ways of sending electronic messages from one networked computer to another. in her study of the internet's origins, Janet Abbate writes that e-mail "remade" the arpanet system and caused it to be see 'not as a computer system but rather as a communication sytem/ (ref.82) 1.[fn:1]

[fn:75] Chip tunes and pixel art

[fn:76] http://cultureandcommunication.org/galloway/rise-of-nondiegetic-media#more-275

[fn:77] http://cultureandcommunication.org/galloway/rise-of-nondiegetic-media#more-275

[fn:78] Is the museum a battle field

[fn:79]
  From Berry:
Template Matching: This is where a computational device uses a set of images (or templates) against which it can compare a data set, which might be an image for example (for examples of an image set, see Cole et al. 2004). Template Matching (Jahangir 2008)

Prototype Matching: This form of patten matching uses a set of prototypes, which are understood as an average characteristic of a particular object or form. The key is that there does not need to be a perfect match merely a high probability of likelihood that the object and prototype are similar (for an example, see Antonina et al. 2003).

Feature Analysis: In this approach a variety of approaches are combined including detection, pattern dissection, feature comparison, and recognition. Essentially the source data is broken into key features or patterns to be compared with a library of partial objects to be matched with (for examples, see Morgan n.d.).

Recognition by Components: In this approach objects are understood to be made up of what are called 'geons' or geometric primitives. A sample of data or images is then processed through feature detectors which are programmed to look for curves, edges, etc. or through a geo detector which looks for simple 2D or 3D forms such as cylinders, bricks, wedges, cones, circles, and rectangles (see Biederman 1987).

Fourier Analysis: This form of pattern matching uses algorithms to decompose something into smaller pieces which can then be selectively analysed. This decomposition process itself is called the Fourier transform.  For example, an image might be broken down into a set of twenty squares across the image field, each of which being smaller, is made faster to process. As Moler (2004) argues, 'we all use Fourier analysis every day without even knowing it. Cell phones, disc drives, DVDs, and JPEGs all involve fast finite Fourier transforms'. Fourier transformation is also used to generate a compact representation of a signal. For example, JPEG compression uses a variant of the Fourier transformation (discrete cosine transform) of small square pieces of the digital image.

The Fourier components of each square are then rounded to lower arithmetic precision, and weak components are discarded, so that the remaining components can be stored in much less computer memory or storage space. To reconstruct the image, each image square is reassembled from the preserved approximate Fourier-transformed components, which are then inverse-transformed to produce an approximation of the original image, this is why the image can produce 'blocky' or the distinctive digital artefacts in the rendered image, see JPEG (2012).

Bottom-up and Top-down Processing: Finally, in the Bottom-up and Top-down methods an interpretation emerges from the data, this is called data-driven or bottom-up processing. Here the interpretation of a data set to be determined mostly by information collected, not by your prior models or structures being fitted to the data, hence this approach looks for repeated patterns that emerge from the data. The idea is that starting with no knowledge the software is able to learn to draw generalisations from particular examples. Alternatively an approach where prior knowledge or structures are applied data is fitted into these models to see if there is a 'fit'. This approach is sometimes called schema-driven or top-down processing. A schema is a pattern formed earlier in a data set or drawn from previous information (Dewey 2011).
