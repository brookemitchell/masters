#+TODO: WRITE EDIT REVIEW | DONE DELETE

* Parasite Suite - Exploring social computing interfaces.
* Introduction
  /Parasite Suite/ is a collection of works exploring possibilities for social computing use in artistic practice. I am interested in the design of boundaries in computing, moments where a technology is abstracted into a user or software interface and how social engagement challenges the requirements of interfacing. The title reflects my preoccupation with the way technology can extract value as a third participant in social interactions. My process has involved studying the experience and aesthetics of computer use and relating these elements to the process of technological mediation described by Martin Heidegger as enframing.[fn:1] Exploring the notion of enframing I seek to catagorise some of the values of computerised social interactions and make them explicit in my work. A particularly focus has been exploring the values and contradictions of hyper and streaming-media in sound art.

   Across all of the works I have focused on using a few key sounds and methods. The sounds are those of the digital voice and the bell. My reasons for these choices are the focus of my work is on communication and social behaviors. These two sounds in particular have a long and complex history in the realms of the social and the surveillant. In both cases I have chosen to use computer rendered, synthesised versions of each. The purpose is to suggest that each is a model of the world, but also that the model changes the dangers and possbilities of their usage.

  The works confront anxiety about social networking structures and question the types of data collection that underpin computerised social interactions. Rather that totally opposing the tools I believe that more interesting, collaborative behaviors can take place when we repurpose the technology and tools in a kind of 'sousveillance'.[fn:2] As such my work is not about confronting power structures direcctly, rather it is focused on awareness and reconfigurations of the tools that are available.[fn:3] Digital processes, such as methods of distinction, have been present in social relations,[fn:4] however present conditions serve to emphasise particular modes that I wish to explore.[fn:5] I believe this is due to the usage of computerised information manipulation tools, so this project must describe both the conditions of computerised social relations and the tools that make this possible. For my project the conditions of social computing are best described as a set of sensation and aesthetic modes privileged by the medium.  While the origin of the factors that influence how we interact with a distributed computer network is beyond the scope of this project, the ramifications can best be described by the dominant metaphors about the network, those of streaming and hyper-media.[fn:6]

  Social computing describes a scenario where information is distributed amongst social collectives.[fn:7] Importantly, this information is not provided anonymously, details and behaviour are linked to identities in a lasting way that defines the archive. Social computing presents unique challenges for interfaces that often goes unacknowledged, unfortunately traditional software design patterns for single user interfaces, are used in place instead of designing for the unique set of experiences and logic. In his summary of the uses of computing, Bret Victor states that there are three primary reasons that people turn to software, for the tasks of, learning, creating, or communicating.[fn:8] Yet in social computing there is a tension of how to design for the convergence of these three kinds of use. With the combination of creation and communication being the most vexed design issue in social computing. This is because as the user becomes a group, the model of the world that is being manipulated is distributed amongst multiple users. In social computing there is often the disturbing sense that the network is gazing into you. Shared understandings of a model change in response to multiple manipulators and information sources, as seen on sites such as Wikipedia.[fn:9] Information that once might be treated as digital crumbs  from the table, has become the most valuable, and are potentially damning traces of social computing behaviour. Drawing attention to these data crumbs for expressive means is a large part of this project.

  I believe that an understanding of social computing can lead to better design and caution over how to design the coupling between computing and users. Changes in interface shift experience, and I argue that this can shift attention to novel or neglected areas. The descriptive phase of this project focuses on researching networked experience and computational aesthetics, two aspects that I believe are key to understanding social computing. The resulting works are focused on contesting the current limits of social computing by expanding art into a multi use, network, inter-relational,  multi-user parties.[fn:10] The project also capitalises on legitimate concerns about social-computing, meditating on the user's sublime tension between awe and anxiety at the networked world. This is due to the way information is indexed, sorted, accumulated and stored, often to be traded and sold, in ways that are left opaque to the user. Data is left to accrue value across distributed sites, and develops usage beyond the present of user interaction. Data accrues value as both an individual object and a member of a collection of trends as information is always linked to an identity, and the relationship of that identity wide collection of metric points of interest. The accumulation and dissemination of this information unfolds in both time and space.[fn:11] I wish to highlight this sense of accumulation in my works and also consider the impact that social arrangements and actions can have on the meaning of this data. I believe that the terms I have adopted, network experience and digital aesthetics, best describe the characteristics and materials of social computing.

  To portray this relationship I will focus on the phenomenological and aesthetic aspects of social-computing. The works use the gallery as a setting for exploring common social-computing techniques, such as data-logging, meta-data extraction, algorithmic sensation and surveillance. These social manipulations hope to provoke consideration of the historical use and influences behind many computation techniques. There are many unexplored or neglected possibilities within computation due to cultural bias and lack of reflexively about the medium.[fn:5] I have been researching two ways technology effects our world, when technology encourages experiences compatible within its own data structures[fn:12] and when it privileges aesthetic trends compatible with its own mode of recognition and reasoning. The presence of these two systems, which I term 'Networked Experience' and 'Digital Aesthetics', are inescapable aspects of how technologies function. However their social and cultural limitations need to be recognised if we are to have any hope of ameliorating the 'false promises of the digital revolution'[fn:13] and develop the more radical potentials of these tools. My small gesture is to reifiy the social manipulations that machines can introduce, and explore ruptures in common computing scenarios in the hope of provoking reflection.

  The starting point for Parasite Suite has been to study common anxieties about the proliferation of these systems. Concerns about institutional surveillance have somewhat reduced the charm of networked computing. References for the works include critical theories of the digital,[fn:14] as well as works by composers and artists with an interest in the relationship between technology and society, such as Włodzimierz Kotoński, Laurie Anderson, Lynn Hershman Leeson, Holly Herndon and Alex Galloway.[fn:15] I believe that phenomenological and aesthetic aspects of social-computation tend to be self-reinforcing, deepening the values that precipitated their own development, to the exclusion of other possibilities. This I term /parasitism/, where a technology invites itself as a third participant in all manner of social negotiations. Appreciating this parasitic relationship with technology, as both hindrance and possibility for exploration, is the first step in developing new relationships with technology.

David Berry argues as networking and software design become the dominant tools for extracting value from the world, we are in a specific phase of enframing.[fn:16] This he terms /computationality/. Inside compuationality, the methods of access, through databases, programming paradigms, data transfer protocols and hardware design, develop serious influence over attitudes to other entities. I argue the present computing climate, defined by the tropes of networking and the logic of pattern recognition, predominates relationships with the self and world. Myself a willing technology user, I do not wish to cast this scenario in a negative light, however awareness is necessary for analysis of social tensions of computing to be brought to the fore. This concept of a mediated relationship with technology, espoused by Berry, is largely an elaboration to the concept of 'enframing' developed by Martin Heidegger in "The Question Concerning Technology".[fn:17]

  I find Heidegger's notion of enframing useful, as opposed to Marshall Mcluhan's notion of mediation. Enframing describes an ontotheology of the world where the use of modern technology as a tool has the effect of mediating access to the world when we depend too deeply on concepts that allow its mastery. This theory focuses on the useage of tools and shows a dynamic, metaphor based realationship with technology and its black boxes, rather than focusing on qualities the medium itslef. It is the mechanism by which the values of a technologies importance tends to propgate through to other technologies. It can be seen often in personal computing, in naturalised assumptions about the deisign of user interfaces or in software design where design patterns are assumed. By creating sound based works that challenge conventions about social interaction  design I believe I can come to some sense of appreciation of the dynamics of social computing.

   Waddington's guide to /The Question Concerning Technology/ explains that Heidegger's work is a breakthrough the way it, "shifts the focus away from specific technologies and toward the modes of thinking that lie behind these technologies."[fn:18] . In Heidegger's theory, modern technology reveals truth as a reserve of energy, in tune with the technical paradigms and values of the time (named in Heidegger's terms as 'standing reserve'). We can do nothing about the arrangement of enframing or its influence, it is built into the technology, we can only consider how we will respond to it.[fn:19]  Heidegger does not state that this should necessarily put us off the use of technology, or define it as a bad thing, rather we need to adopt an attitude of 'releasement' (the ability to have a deferential attitude, or apathy, towards the necessity of a technology), that he finds most important.

   The mechanics of enframing are dependant on two kinds of 'concealment'. The first is the intentional abstraction of lower level mechanics of a technology, as is the purpose of any interface. This abstraction of machinic process allows the technology to be used instrumentally or interact with other technologies, often seen in music composition and software design when we abstract complexity or use a software library to focus attention upon a previously unreachable area. There second type of concealment is described as a more dangerous kind of concealment, which Heidegger calls 'concealment of the concealment'.[fn:20] It is the taking for granted of a technological abstraction or tool. The first abstraction is becomes a given, to the point being treated as simulacrum of the representation, such that its technological underpinnings and social epoch are unable to be analysed, doomed to be treated as 'natural'. This second act of concealment is regarded as more insidious, unique to modern technology, and most importantly able to be repudiated through awareness.

   In our parasitic relationship with technology; abstraction advances understanding, yet doing so can dominate our experience and potential. One of the goals of most software is to achieve a simulacrum of 'realness', modelling the process it is imitating, to the point of often being indistinguishable.[fn:21] A successful technology can 'disappear', becoming unacknowledged facilitator of experience. This is particularly the case with imitative and surveillant techniques. Studying networked experience and digital aesthetics reveals instances of the second kind of concealment in common technologies. Through manipulations techniques I hope to 'de-black box' a number of social-computing scenarios, focusing on experience and aesthetics. My definition of an interface applies to any abstraction which encapsulates an  more complex set of operations into a handle. Interfaces are doubtlessly important and necessary, however in social interface design the sharing of information between both humans and applications is many times needlessly constrained, often intentionally so to be siloed and collected. Due to this the experience of computerised social networks goes beyond the dichotomy of online and offline worlds, as our actions and their resultant data accrue value. The extraction of digital labour points to an attitude toward the world highly influenced by some values that coalesce in the tools for this use. I am seeking to encourage responsive engagement and misuse of works that echo many of these common engagements.

* Networked Experience - Feeling and machines.

   Networked experience is my term for the phenomenological aspect of social computing. In a networked experience, algorithmic processing is a facilitator of sensory perception. Video games, pornography, shared coding environments, networked music and robotic surgeries are all examples of the emergence of networked sensory systems. Often an interface design is metonymic in its choice of sensory paradigms, choosing to emulate tools associated with the object it is modelling, such as the paintbrush metaphor in Photoshop.[fn:22] However occasionally an experience like email radically changes practices of design at multiple levels. Here interface design, text layout and communication protocols have all adapted to social interaction.[fn:23] Like print, radio and film were previously, the internet acts as a super-medium, containing other media.[fn:24] It envelops media such as newspapers, books, television, games and radio as content, while modifying aspects of their aesthetics and meaning. Importantly, the types of alterations are derived from the enveloping medias methods of access to content, they can be streamed, or hyper media, or both.

Hyper media offers non-linear user-customised content. In the full definition of hyper media, it is content with multiple levels of referencing, levels of details, user definable paths of access, editing and manipulation.[fn:25] It is the ability to manipulate content at multiple levels that I see as important. Streamed media is that which is delivered and presented by connecting to a provider, without the need (or with the ability removed) for user storage. It is a process of delivery and rendering rather than a tool in itself and can happily coexist with hypermedia. In practical terms however this is often not the case, as providers have control of content and few are willing to allow users to make direct changes to the media, particularly for multimedia. Describing the experiences that hyper and streamed media create, common characteristics of hyper-media are: cross-referencing, editing, the ability to alter levels of detail, with links between each of these revisions and a sense of collaboration inthese actions.[fn:26] Characteristics of the stream are information aggregation, feeding, tracking, buffering, chunking, re-ordering and exhaustion. Although there is a rich variety of media types on the internet, it seems though it is text that is by far the most hyper, in its ability to be distributed, cross referenced, linked and have form separate from content. Aspects of this are open to remedy, and in the sound world this has driven my interest in the Web Audio and MIDI APIs.[fn:27]

Streaming has risen to become the paradigmatic method of access today according to David Berry. Defining the metaphors of computerised enfaming. The paradigmatic metaphors are real-time, and flow, both metaphors that think of the digital as moving with trajectories and velocities. It is also a process of 'exhaustion', where a resource is divided into chunks, in the case of TCP/IP delivered into an unpredictable order, with a 'best attempt' at delivery.[fn:28] The packets then need to be checked by an algorithm, so bits can be re-requested, deleted and re-ordered. It is the computation encoding of a post-fordist, 'just in time' re-assembly of digital assets. The experience of streaming systems often makes information seem an immaterial vector, with only velocity and direction, and one that can be accessed by turning on a tap and directing the flow. The metaphors of streaming can make all other objects seem like streams of information, waiting to be broken into chunks and waiting for acknowledgement. This can be seen in the emergent paradigms new computer programming languages [fn:29] that emphasises the metaphor of piping, whereby modules are connected to transfer an awaited stream of information. Berrys's term for this type of experience is 'streaming-forth', as the network  becomes the characteristic mode-of-revealing of nature. 'Streaming-forth' is an expectation for entities to reveal themselves in terms derived from metaphors about computation.

 We have seen the rise of process piping and streaming beyond the realm of software design.[fn:30] This process is effecting other areas, as software companies attempt to bring their approaches to software into traditional institutions such as education and the home.[fn:31] Berry terms this mode of thinking about access to the world, 'streaming forth', where the demand placed on the world is that of constant re-ordering, processing and collection, rather than the challenge-response model of Heidegger conception of the influence of electrical tools. The mode of streamed experience isn't dependant on any kind of technology or state of development, it is possible to create a these kind of experiences entirely with a set of human relations. This was the case with Cyber-Syn a 1970's project by the Chilean government to create cybernetic economic systems, modelled on the human nervous system, realised by and large without computer access.[fn:32] Streaming describes an attitude towards access to resources, it is an enfraing we expect the methods of access for streaming to apply in all our relations.

   This sensory approach, applied to computing, is closely associated with both cybernetics, as shown in Eden Medina's study of early attempts art providing experience of the economy as a nervous system in Peron's Chile.[fn:33] The streamed experience is often a flawed fantasy of the eternal present, where the individual instinctively responds to events in a consumerist haze. However there were wider possibilities, such as those that were the original intention of the Cybersyn network to provide multi-faceted levels of experience and direction, with attempts to emulate cognitive, self-sustaining and pre-emptive modes within the different levels of the cybernetic organisation. I wish to argue that it is not the mechanics so much as the purpose for the use of these tools that is lacking. Streaming tends to engage in concealment of resources, transport mechanisms and ironically, the participation of other users. This can be seen in the somewhat humorous technologies such as 'The Twitter Sort,'[fn:34] and the word processor Soylent[fn:35] "The word processor with people inside," where users of Amazon's distributed micro-labour system Mechanical Turk[fn:36] perform word processing operations. Rather than rejecting the phenomenon (which I feel is impossible) I am interested in what aspects are open to social manipulation when this kind of thinking is dominant. The easiest way to decide what elements to focus on are to look at the concealment that a technology makes. I think that accumulation and memory are the first to be ignored, as are the material needs of a technology.

   As networked experience extends beyond interaction with computers, into a metaphorical 'revealing' of the world as a network of social scenarios, able to be connected, as long as users are cognisant of the rules of interaction. This kind of ethos is enabled by the design values embedded in computer hardware and software, as influenced by the Californian ideology and the notions of individualistic libertarian impulses that theory entailed.[fn:37] Network technology under these paradigms imbues it with a particular kind of immediacy, but also a sense of danger. It is a de-regulated system that places a heavy burden on users to manage and secure all aspect of their online identity.[fn:38] The contradiction that we often use networks to maintain the notion of individual identity, which is often where it is taken away, seems strange, but I believe the implementation of values in software and hardware is the reason. This is no conspiracy, simply that the standard practice is to reproduce and emulate the models of the past, and programmers are often excellent at emulating a narrow range of design patterns.[fn:39] My project explores this tension between streaming, and hyper-ness. I wish to see the realisation of an interconnected stream of audio that can exist at multiple levels of detail, with links to references, branching and responding. I wish to explore the sensory process of the stream, how it fits into social surveillance and hyper-media, to combine these into a kind of fused media that uses some of the inherent contradictions in the 'feeling' of the stream.

* Abductive Aesthetics - Computed Ontology
  In contrast to the immediate aspects of networked experience, digital aesthetics are the lasting effects of social computing on reasoning and judgement,[fn:40] a rupture of the digital into the real. The effects of this kind of thinking can be seen clearly in the structure and trends of digital works. Often termed 'pattern aesthetic'[fn:41] or 'the new aesthetic'[fn:42] these trends describe widespread cultural shifts in appreciation of objects that bear a hallmark of their interaction with computer algorithms. The most noticeable of these are nostalgic aspects to older computational limitations, such as pixelated artworks and chip-tunes.[fn:43] Popular trends in architecture, photography and music also bear signifiers of digital logic, often by artists the highlighting of the presence of digital tools, Hito Steryl notes the impact of digital modelling tools on the designs of Frank Gehry.[fn:44] Similarly the modern history of dance music shows a particular desire to highlight the impact of tools such as particular models of drum machines. David Berry names this 'Abductive Aesthetics', arguing that the particular logic used in software design informs the look of the digital rather than the popularity of a particular style. This logic is known as abductive reasoning.

  Abductive reasoning, also known as inference to the best explanation, is an approach to reasoning which attempts to test a hypothesis based on the information at hand. For computers it involves continuously refining the set of best guesses as the quality of information improves. It can be contrasted with deductive (proof-based) and inductive (evidence based) reasoning as the fuzziest kind of reasoning, somewhat akin to a 'best guess'. It is ubiquitous in its use by computers, one of the most well known examples of an abductive algorithm is predictive text on cellular phones, but abductive reasoning is a process of distinction used everywhere in computing. Early research on artificial intelligence focused heavily on the use of abductive reasoning.[fn:45] One of the reasons for doing this was to design functions that could handle large data sets without having to maintain state. Maintaining state is akin to keeping track of changes in variables as a progression of events takes place, which becomes unwieldy with a big data set. Abductive reasoning emphasises the spatial over the temporal by avoiding the recording of data within its functions, instead focusing on its mathematical operation to return a new configuration of a data space.

  I am seeking to apply abductive logic as more than a tool by looking at its form and social impact. For this project I wish to explore the application of digital logic to artistic and musical composition and its resulting aesthetic, as well as possibilities for reaching beyond this. Applying abductive reasoning to music, the resulting aesthetic experience can be described as conducting a specific kind of 'pattern language'. It would be a pattern language based suggestions and rapidly testing a hypothesis. Similar to  jumping to conclusions until all our tests for truth pass. To act abductively with music, I believe we need to design musical systems that collect information and respond with a best match.

  A 'pattern language' is something that we can be aware of, but whose methods try to make themselves invisible to us. This desire for invisibility goes beyond the user interface level to all manners of coded space: interfaces, application programming interfaces, objects, macros, function composition, integrated circuits, all exist as abstractions that can make an processes result seem more natural when they hide away complexity. These tools are crucial for managing all of my projects, however the cumulative effect of these tools, often appears as a kind of 'magic' to the person using the tool to prepare an experience, Later they begin to seem 'natural' to the end user, who is intended to be none the wiser. Social interfaces can then be experienced as a combination of computer processing and networking capability that embody a particular aesthetic and set of practices for those that interact with the works.[fn:46]  A particular aspect of the computational I have focused on is the felt sense that a machine can be treated as a participant and social actor rather than a tool.

  What abductive reasoning offers in difficult to parse patternings. A condition exemplified in the social. Abductive recognition does not focus on the time-line of events, to find an implication, but rather on the spatial characteristics of a set of values, for instance if they match the qualities of a matrix of vectors. The aesthetics of abductive reasoning can be thought of as consisting of several model types, each with their own characteristics, but a common thread of converting actions over time into a spatial arrangement. These pattern matching patterns, are broadly outlined by Berry as template-matching, prototype matching, feature analysis, recognition by components, Fourier analysis, and lastly bottom-up and top-down processing.[fn:47] By using abductive reasoning as a composition tool we can see the process of recognition in action, and begin to think about its effect. The characteristics which I wish to bring to my art works are those of spatial, speculative, and generative. Abductive reasoning invites us to consider a algorithms image of the world, and what these algorithms mean to us as ways to regulate our behaviour. This approach to reasoning and experience is deeply connected to the history of computation, particularly that leading to the development of the personal computer.

* Parasite One
** Summary
   This installation takes place on a staircase, occupying seven stairs. Each stair has a floor trigger underneath with adjacent light source to illuminate each stair as a participant passes through the space. Hidden under the staircase sits a speaker that plays a different section of a vocal phrase as the participant stands on each step. The sound that plays at each stair is a gated segment of a long, looping Vocaloid vocal track, in which a computerised voice sings a tale of its work for the day. There is also a website for the installation where users can log on to observe the space and listen to the installation. Access to the website also offers users two other elements of added functionality. After allowing access to a users microphone and camera, they can now trigger staircase responses remotely, by hovering or toxing a translucent box overlaying the visual image of each stair.

The computer is set to turn on the 12 volt lights attached to each stair in response to either an action on the website or physical trigger. The website is also constantly looping through seven chanels of audio, each channel its volume output gated to sound when a user stands upon a floor sensor. At the top of the stairs, visible to those ascending, there is a handwritten universal resource locator (URL) directing those who are interested to visit a web page. [fn:48] By participating online the user also becomes part of the installation, the sounds of their microphone stream replace those of one of the stairs in the installation, for as long as they are visiting the site, but only triggered if they select their stair or a user stands upon the floor sensor. The stair whose sound a user becomes is dependant on the time of day they visit the site and the number of current users. Over the course of the installation, the sung elements begin to degrade and fragment according to the data collected on the usage of the stairs, which collates both physical and virutal users as they 'wear' down the sounds on each step.

 The observed experience is distinct but shared for the two types of participants. In-situ visitors are usually surprised by the hidden apparatus and illumination of their movement. There is an element of digital fantasy that gives way to the more concerning on repeated visits as the sounds begin to wear and fade. For the virtual visitor there is a similar shift in mode, as at first the power to survey and control gives way to a disembodied self, as they begin to occupy the space that they are surveying and add artistic purpose to the work through their engagement. Some  of the principal sources of inspiration are a of John Cage's Imaginary Landscape Number 5,[fn:49] This re-imagining of the work is also inspired by the oblique and text-less the player networking system of the video game Dark Souls[fn:50], the 'cut up' word techniques of William Burroughs, as well as novelty 'giant' piano featured in landmark toy stores, used in sequences from the movies Big[fn:51] and Lethal Weapon.[fn:52] Taking these elements and exploring the sensory and aesthetic possibilites of network and attempting to convey some of the anxiety and novelty to users sonically is the driving force of the work.

** Technical Outline

   Custom built floor panels are placed under pieces of carpet and wired to the General Purpuse In/Out (GPIO) pins of a Beagleboard embedded computer. The Beagleboard manages the pins using its built in microcontroller chip, while the embedded computer serves the website at http://1.parasite.club. The computer is also scripted to open a local web page that responds to webSocket messages and manages audio output. The local page is set to loop seven channels of sound within the space using the audio capabilities of a Web Audio Application Programming Interface (APIs). The floor sensors serve as basic buttons, they are connected to seven digital inputs on the Beagleboard, using the internal pins of each pin to serve as pull up resistors. To control the lighting seven digital outputs send 3.3v control voltage signals to transistors, each gate a light's power, provided by a separate power rail. Should either a webSocket message or button press be received, the web page is set to gate the sound of teh appropriate loop, and the Beagleboard to light the correstponding lighting strip.

   The server on the computer manages the major communication aspects of the installation, those being communication with the GPIO pins, handling web requests and bi-directional socket communication with users once the page is recieved by the client. WebSocket communication enables two-way real time communication over an persistent connection between server and client. [fn:53] The third protocol is the management of real-time audio-video communication as handled by the Web Real Time Communication Protocol(WebRTC), which enables a teleconferencing like arrangement to be quickly established so that users can monitor each other and the server. All of these communication aspects are each handled within the node.js server-side language. In addition to this a small logging system is used to store user behaviour for later analysis processing and scripting of audio processing, while a cloud based archiving system exists to store video archives.

At a predetermined each day a small script is run that applies a transformation from the Composers Desktop Project to the streams of audio on the basis of usage for each stair. The script is set to remove the loudest frequencies from the spectral domain and average the quieter frequecies slightly if the stair has been used, multiplying the effect of the basis of usage. The extend of modification is designed to be very slight, with the intention of the sound only reaching its full 'blurred' state, on a rough average over a period of thirty days. After 30 days the sounds are reset to their initial state.

 The website uses the Johnny-Five library to allow the server to communicate with the computers on chip mircocontroller. The requirements for the Beagleboard chips embeded microcontroller in this instance are to register any floor sensor button presses, log them and send a digital 'high' message to the transistor corresponding to the light. The second requirement is to send this message as a webSocket broadcast, so that each clients interface reflects the current state of the system. The other requirement is to receive any webSocket messages. Users who visit the web page are served a unique interface from the Beagleboard. This page contains a real time video of the room as well as the necessary authentication tokens for them stream their own media. To provide the dynamic content the express library backend generates the custom html necessary. In this case the process is relatively simple, with the content being a largely static page augmented with dynamically generated user tokens and statistics for the extra protocols and logging system. The small log displayed to users shows the identity details of recent users, an IP address, location, hardware details, name and time of day and length of access for other users.

 The socket.io library manages webSockets providing a more manageable abstraction for dealing with asychronous realtime messages. As the name implies, the library forms the core of the input/output messaging system of the installation by relaying messages in real time between disparate users and the server. The library can therefore manage all aspects of the chat application and user hover actions. Keeping track of users and their states and broadcasting these messages to all participants as well as broadcasting button triggers on the stairs to all website users. The web server provides two web pages, one outwardly facing root of the web site, which serves the main client side application, a chat room with real time audio/video communication. The second page (henceforth referred to as the 'host' page) is served is at  an undisclosed url that provides audio functionality for the staircase and intended only for use in a scenario where a computer is connected to a webcam, speakers and microphone, although the possibilities of 'hacking' the host page is left open due to its publicly accessible address.

The 'host' page is primarily designed to contain a web audio API 'audiocontext' link to appendix describing web audio api) that is controlled by webSocket messages to turn gain nodes on and off, a buffer and gain node corresponding to each step. This buffer initially contains a long (seven minutes or more) field recording. As users step on floor sensors or web client users hover over a set of seven boxes , the corresponding gain node of a stair is un-muted. The 'host' page's user functionality is minimal and specifically designed around the needs of the installation, providing appropriate responses to websocket messages by raising the gain of audio streams if told to by the server or another client.

* EDIT Parasite Two
** Summary

   Parasite Two is a audio/visual installation that combines a interactive topographic rendering with a sequencing and synthesis system. A projector and depth sensing camera are mounted over a box of sand, connected to a computer and speaker system. A topographic relief map is projected onto the surface that is able to be interactively reshaped by the user. This landscape informs the process of stochastic synthesis as the surface is scanned, while the steepness of the relief determine the speed of movement of the scanning and density of topographic lines triggers events.

   The installation involves a large glass box containing white sand, with speakers and a computer placed adjacent. Above the sandbox a projector and depth sensing camera are mounted. The camera senses the depth of the sandbox surface beneath and overlays a set of topological data. The contours are treated as a series of waveforms that are rendered by the musical system. The participant is placed into the role of composer of landscape and given a kind of god like view over the environs. The installation is designed to be used by multiple particpants at once, and users can cooperate or work against each other. In a similar manner the resources of the camera and projector feed are shared by the computer applicaitons. The sound sequencing and rendering system is based on the work of Iannis Xenakis.[fn:54]

 The works aims to consider the raltion between the camera, participant and interaction. Lev [] argues that new media is focused on the camera. Here we expand this to a three dimensional camera and create a landacape based on a model of what the camera sees. The networking and social interaction that takes place here isn't connected across the internet, rather it is local feedback loop of user manipulation, that incorperates the thought process of social networking.

 Parasite Two is an attempt to incorporate computational and networked approaches to photographic intelligence as a method for musical composition. While Parasite I focused on communications intelligence and interpersonal relations, Parasite II is centred on Photographic Intelligence [PHOTINT] as a musical method and inter-application communication within the machine. Also commonly known as Imagery Intelligence [IMGINT], this kind of intelligence and analysis is commonly associated with Satellite photography and drone warfare. In this installation I seek to use methods derived from the history of technology in this field in order to create visual consideration of landscape and topology that become musical environments.

Part of the creative inspiration for the project is in the arrangement of communications between disparate software programs. as they share their contexts as they seemingly operate in parallel. Each program uses the same sensory information but styles it using a different logic and syntax that informs the audio and visual outcome. This is an early form of what Manuel DeLanda has termed a 'Pandemonium'[fn:55] . In its ultimate form, processes would operate as small modular forms of artificial intelligence. As it is experienced in the gallery context, the sensation of effecting both audible and visual landscape is hoped to be both thrilling and mildly sinister.

** Technical Outline

   The installation consists of a open top glass box of dimensions 0.75meter x 1m x 0.15 meter depth, filled with 50 kilograms of white sand. Directly above the box a short-throw projector and depth sensing camera (Microsoft Kinect) are mounted. These are connected to a desktop computer running Linux with a graphics card and audio output. The visual rendering software is SARndbox, an augmented virtual reality system developed by Oliver Kreylos at the  University of Davis California Geology Department. [fn:56] The software forms a feedback loop as the calibrated information from the camera becomes topographical data which cn be adjusted in real time by altering the depth of the sand surface.

   A custom version of the SARndbox software has been compiled that add the features of Open Sound Control to the software. From this the depth matrix of the sand surface is constantly transmitted over a port to be used by the IanniX[fn:57] three dimensional sequencer and SuperCollider. The signal from the Microsoft Kinect is also sent to a custom version of the IanniX  sequencer. The software is a modern implementation of Iannix Xenakis HPIC visual arrangement system. Iannix takes the matrix of depth values from a Kinect camera and creates a set of topographic intervals, which act as the set of curves that control the synthesis. Along each curve travels a cursor, meaning the can be a massive number of cursors all moving at different rates.[fn:58] The position of each cursor is relayed over OSC to  the audio rendering system, collisions between curves are also able to be detected, forming events.

 The sound is rendered using an implementation of Iannis Xenakis' GENDY stochastic synthesiser.[fn:59] The GENDY system will map sets of control points to contours of the landscape, with elevation determining the event distribution and amplitude. Collisions between cursors are seperately rendered and triggers for vocal samples of digital singers emulating the sound of bells.

* WRITE Parasite Three
** Summary

   Parasite Three is a performance work that takes a collection of the materials collected in the other works and explores their real time performance possibilities. The work uses a haptic interface to physically render the network as a collection of physical vibrations, while automated recordings from the installations are sequenced according to the analysis of each installations logs. The purpose of the work is to give a performance that conveys the themes of the other installations and embeds myself deeper within the practice of networking as art. Before the performance a short talk is given explaning the materials and methods.

 The works materials are a collections of media, data, logs and streams from the other installations. The intention of the performance is to convey a real time summary of network activity in the present space, as well as a sonified summary of the events that have been logged by the installations.

 The performance computer is runing a piece of sofware that tracks network activety at the nearest router and converts them to OSC messages, while a script is run against the data logs from the previous installations and summarises its finding as a set of OSC mesages that are broadcast to other applications.

Hit the logs.

 Also other qualities, like the kinds of messages can be deduced by comparing the byte length characteristics of the packages to deduce the application layers that are being predominantly used. In this way the work seeks to look at information and the shaping of messages as a hybrid process in which aesthetic choices, technological capabilities and social signalling processes are all complicit. It is hoped by choosing 'alternative' and more experimental practices for live performance, that some of the common tropes and negotiated meanings that are also in more regular practices can also be noted. The performance focuses on the performer managing the emergent properties of the network and finding a manner to interact with the 'possibility space'.

** Tech Outline

The performed work uses three channels of information rendered into a stereo output. The first channel is a series of samples which are collected from the online users of the Parasite I. For each user audio clip taken and the corresponding log entry of behavior is sung by the computer using the voice synthesis software along with vocal renditions of a bell. The samples are played basing using the CosmosF stochastic Sequencer and Synthesiser developed by Sinan Boksoy.[fn:60] The software is an opinionated interpretation of the work of Xenakis in Formalised Music, to have a multi level (micro meso macro) stochastic sequencer that also contains a stochastic synthesis engine and represents a massive effort into developing the concepts of stochastic approaches to music by Dr. Boksoy. I take a limited approach to utilising the software, focusing exclusively on the use of samples whose duration and onset are stochastically controlled. The relevant parameters are mapped to a faderfox FX3 controller.

The second channel uses an instrument designed specifically for the performance, the Firefader,[fn:61] an open source haptic interface developed by Edgar Berdhal. The instrument is comprised of two motorised faders with capacitive sensing to ascertain when a user touches one of the faders. After registering that the performer is touching the interface, the network activty messages received are translated to weight forces on spring models, these in turn strike resonant bell models which are placed at fixed points along the cpntinuum of the faders travel. The forces on the springs will cause the faders to move and strike the bells of their own accord, however the forces can alsop be strugged and gainst and the force of a strike is reflected int he output of the bells physical model. The tuning schemes of the bells correspond to an analysis of the vocaloid excerpts.

The third channel is a simple monophonic synthesiser over which a response can be improvised.

* WRITE Conclusions

We expect infterfaces to e mostly informational, and this is true. Manipulation is hard and confusing. However we often dont' realise that we are often productng much more thn we realise, and even mainitaining the domnant ios aform of creative conststruction.We shoul de more critical about the tools f everyday life, they are often hyper- tools without us even realise it, and shaping our understandinging. Call for a change in tools. A thing of internets. Mroe than one way to skin a cat.
Virtual subjectivities vs virtual objects
distinction between on and offline is false. the method of access has already changed our attitude to information and existance.

  What is understanding, vs. mastry. Is understanding deep exploration
  Pay attention to the social dynamic of the tools that you have.

Shift understanding. Hyper into understanding, stream into contingency.

  Question of even presenting the material. Is digital art a performance, I would argue it is, and that there is a neglected temporality.

  Danger is in emphasising mastry over and about understanding. How over why. Computers are always social.

  Technology as more medium than instrument, instrumental thinking as problematic.

is particular association is identified in “The Question Concerning Technology,” where Heidegger says that as long as we perceive “technology as an instrument, we

remain held fast in the will to master it.”9 A similar theme is taken up and examined by Heidegger in What is Called Thinking?10 Within this text, Heidegger pronounces that Nietzsche’s overman represents the embodiment of pure technological being, insofar as the overman’s will is a will that strives to dominate and master anything that is other.11 Heidegger feels that the overman is not an anomalous phenomenon in the modern technological age. All those who live under the sway of modern technology have to confront this reality. Within the periphery of the epoch of modern technology, “the only thing we have left is purely technological relationships.”12

  The end goal is the hope tat users will envisage teh ways in which existing social engagements can be 're-tooled'. The 'hack' of technology is often not highly technical, instead it is a re-visioning of what a technology could be useful for.

* Footnotes

[fn:1] Enframing

[fn:2] Sousveilllance link

[fn:3] Webpage of dig anth lady

[fn:4] See Galloway Laurel

[fn:5] Link to magic words.

[fn:6] Durther avenues to pursue for more details

[fn:7] From "Social Computing", introduction to Social Computing special edition of the Communications of the ACM, edited by Douglas Schuler, Volume 37 , Issue 1 (January 1994), Pages: 28 - 108

[fn:8] http://worrydream.com/MagicInk/#manipulation_software_design_is_hard

[fn:9] Wikipedia

[fn:10]

[fn:11] From "Social Computing", introduction to Social Computing special edition of the Communications of the ACM, edited by Douglas Schuler, Volume 37 , Issue 1 (January 1994), Pages: 28 - 108

[fn:12] Paper on organisation structure effecting software design

[fn:13] False promises of Dig Rev

[fn:14] Theories of the Digital

[fn:15] Put refs for all tehse people here

[fn:16] Heidegger notes in /Being and Time/ that the priveleging of the present has a *parasitic* relationship with the concept of time. This could be extended.

[fn:17] heidegger qct

[fn:18] Waddington 577
Heidegger also noted that "it is possible to focus on the thinking behind the technology to such an extent that meaningful distinctions in the world are obscured."[fn:21] This remark was originally a part of ‘The Question Concerning Technology’, but later excised.[fn:67]

[fn:19] Enframing Heidegger p.2

[fn:20] Second ceoncealment Heidgger

[fn:21] Waddington 577

[fn:22] Ref to Application layer of TCP/IP

[fn:23] /E-mail emerged in 1971 when users began experimenting with ways of sending electronic messages from one networked computer to another. in her study of the internet's origins, Janet Abbate writes that e-mail "remade" the arpanet system and caused it to be see 'not as a computer system but rather as a communication sytem/ (ref.82) 1.[fn:68]

[fn:24] Berry on 'super-mediums'

[fn:25] See Ted Nelson hyper media

[fn:26] Nelson Dream Machines

[fn:27] Web Audio API

[fn:28] See the deisgn of TCP/IP, also md5 sums

[fn:29] Streams Programming Languages

[fn:30] See streaming in js, matz pipe language

[fn:31] Agile family management

[fn:32] ref to dependdence on human actors in cybersyn

[fn:33] Cybernetic Revolutionaries

[fn:34] Twitter Sort

[fn:35] Soylent web site

[fn:36] Mechanical Turk

[fn:37] Link california ideology works

[fn:38] /The visions of a free, uncensorable cyberspace envisioned by Barlow, Gilmore and others was incompatible with the needs of Capital, and thus the libertarian impulses that drives Silicon valley caused a change in tune. Cyberspace was no longer a new world, declared independent with its own unalienable rights, it was now an untamed frontier, a wild-west where spooks and cypherpunks do battle and your worth is measured by your crypto slinging skills and operational security... This, as Seda Gurses argues, leads to Responsibilization... Users themselves are responsible for their privacy and safety online. No more unalienable rights, no more censorship resistant mass networks, no more expressing beliefs without fear of being silenced. Hack or be hacked./[fn:74]

[fn:39] repetition of design patterns

[fn:40] (digression on culture)

[fn:41] Pattern Aesthetics

[fn:42] the new Aesthetics

[fn:43] Chip tunes and pixel art

[fn:44] Is the museum a battle field

[fn:45] link between abductive reasoning and ai.

[fn:46] link to uses of term

[fn:47] From Berry:
Template Matching: This is where a computational device uses a set of images (or templates) against which it can compare a data set, which might be an image for example (for examples of an image set, see Cole et al. 2004). Template Matching (Jahangir 2008)

Prototype Matching: This form of patten matching uses a set of prototypes, which are understood as an average characteristic of a particular object or form. The key is that there does not need to be a perfect match merely a high probability of likelihood that the object and prototype are similar (for an example, see Antonina et al. 2003).

Feature Analysis: In this approach a variety of approaches are combined including detection, pattern dissection, feature comparison, and recognition. Essentially the source data is broken into key features or patterns to be compared with a library of partial objects to be matched with (for examples, see Morgan n.d.).

Recognition by Components: In this approach objects are understood to be made up of what are called 'geons' or geometric primitives. A sample of data or images is then processed through feature detectors which are programmed to look for curves, edges, etc. or through a geo detector which looks for simple 2D or 3D forms such as cylinders, bricks, wedges, cones, circles, and rectangles (see Biederman 1987).

Fourier Analysis: This form of pattern matching uses algorithms to decompose something into smaller pieces which can then be selectively analysed. This decomposition process itself is called the Fourier transform.  For example, an image might be broken down into a set of twenty squares across the image field, each of which being smaller, is made faster to process. As Moler (2004) argues, 'we all use Fourier analysis every day without even knowing it. Cell phones, disc drives, DVDs, and JPEGs all involve fast finite Fourier transforms'. Fourier transformation is also used to generate a compact representation of a signal. For example, JPEG compression uses a variant of the Fourier transformation (discrete cosine transform) of small square pieces of the digital image.

The Fourier components of each square are then rounded to lower arithmetic precision, and weak components are discarded, so that the remaining components can be stored in much less computer memory or storage space. To reconstruct the image, each image square is reassembled from the preserved approximate Fourier-transformed components, which are then inverse-transformed to produce an approximation of the original image, this is why the image can produce 'blocky' or the distinctive digital artefacts in the rendered image, see JPEG (2012).

Bottom-up and Top-down Processing: Finally, in the Bottom-up and Top-down methods an interpretation emerges from the data, this is called data-driven or bottom-up processing. Here the interpretation of a data set to be determined mostly by information collected, not by your prior models or structures being fitted to the data, hence this approach looks for repeated patterns that emerge from the data. The idea is that starting with no knowledge the software is able to learn to draw generalisations from particular examples. Alternatively an approach where prior knowledge or structures are applied data is fitted into these models to see if there is a 'fit'. This approach is sometimes called schema-driven or top-down processing. A schema is a pattern formed earlier in a data set or drawn from previous information (Dewey 2011).

[fn:48] WebPage addr.

[fn:49] Cage Imaginary Landscpe No. 5

[fn:50] Dark souls

[fn:51] Movie Big

[fn:52] Lethal Weapon

[fn:53] WebSocket protocol.

[fn:54] Xenakis Formalised Music

[fn:55] Delanda Pendemonium

[fn:56] SARndbox

[fn:57] Iannix

[fn:58] Iannix manual

[fn:59] GENDY link

[fn:60] CosmosF

[fn:61] Firefader

[fn:67] (Harries, 1994, p. 233) IN Waddinton 577

[fn:68] edina 64

[fn:74] www.dmytri.info/hackers-cant-solve-surveillance/
